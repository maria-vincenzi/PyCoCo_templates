{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Dim Gaussian Interpolation\n",
    "### Sub-steps:\n",
    "**1)** *Build the grid time x wavelength using flux calibrated spectra, UV photometry and optical photometry (only where spectrophotometry is sparse)*\n",
    "\n",
    "**2)** *Model the data using 2dim GPs and determine the 2dim interpolated surface*\n",
    "\n",
    "**3)** *Predict UV extension for your sparse spectrophotometry*\n",
    "\n",
    "**4)** *Predict additional spectra at the phases where spectrophotometry is sparse (FROM sparse spectrophotometry ---> TO spectrophotometry with high and homogeneous cadence)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "COCO_PATH=os.environ['COCO_PATH']\n",
    "DATALC_PATH = COCO_PATH+\"/Inputs/Photometry/4_LCs_late_extrapolated/\"\n",
    "DATASPEC_PATH = COCO_PATH+\"/Inputs/Spectroscopy/\"\n",
    "\n",
    "DATAINFO_PATH= COCO_PATH+\"Inputs/SNe_Info/\"\n",
    "FILTER_PATH = COCO_PATH+\"Inputs/Filters/\"\n",
    "\n",
    "OUTPUT_DIR = COCO_PATH+\"Outputs/\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, COCO_PATH+'what_the_flux/')\n",
    "sys.path.insert(0, COCO_PATH+'/Codes/')\n",
    "import what_the_flux as wtf\n",
    "import GP2dim_utils as GP2dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "from numpy.linalg import inv\n",
    "from scipy import misc\n",
    "\n",
    "import math\n",
    "\n",
    "import scipy\n",
    "from scipy import interpolate\n",
    "from scipy import integrate\n",
    "import scipy.optimize as opt\n",
    "from scipy.optimize import minimize\n",
    "from itertools import cycle\n",
    "\n",
    "import george\n",
    "from george.kernels import Matern32Kernel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSP_SNe = ['SN2004fe', 'SN2005bf', 'SN2006V', 'SN2007C', 'SN2007Y',\n",
    "           'SN2009bb',  'SN2008aq', 'SN2006T', 'SN2004gq', 'SN2004gt',\n",
    "           'SN2004gv','SN2006ep', 'SN2008fq', 'SN2006aa']\n",
    "pre_bump = ['SN2011dh','SN1993J','SN2008D','SN2011fu','SN2006aj','SN1987A','SN2013df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_dict = {'Bessell_U': 'blue', 'Bessell_B': 'royalblue','Bessell_V':  'limegreen',\n",
    "              'Bessell_R':  'red', 'Bessell_I':  'mediumvioletred',\n",
    "              'sdss_g':'darkgreen','ptf_g':'darkgreen', \"sdss_g'\":'darkgreen','sdss_i':'indianred',\n",
    "              \"sdss_i'\":'indianred','sdss_r': 'darkred', \"sdss_r'\":'darkred','sdss_z':'sienna', \"sdss_z'\":'sienna',\n",
    "              'sdss_u': 'darkblue', \"sdss_u'\": 'darkblue', 'Y':'salmon','H':'darkred', 'J':  'k',\n",
    "              'Ks':  'brown','K':  'brown', 'swift_UVW1':'indigo', 'swift_UVW2':'darkblue',\n",
    "               'swift_UVM2':'darkmagenta','swift_U':'plum','swift_V':'teal','swift_B':'powderblue'}\n",
    "\n",
    "mark_dict = {'Bessell_U': 'o','Bessell_B': 'o', 'Bessell_V':'o', 'Bessell_R':'o', 'Bessell_I': 'o', \n",
    "             'sdss_g':'s','ptf_g':'s', \"sdss_g'\":'s', 'sdss_i':'s', \"sdss_i'\":'s',\n",
    "                'sdss_r':'s', \"sdss_r'\":'s', 'sdss_z':'s', \"sdss_z'\":'s', 'sdss_u': 's', \"sdss_u'\": 's',\n",
    "                'Y':  'o','H':  'o', 'J':  'o', 'Ks':  'o','K':  'o',\n",
    "                'swift_UVW1':'D', 'swift_UVW2':'D', 'swift_UVM2':'D', 'swift_U':'D',\n",
    "                'swift_V':'D', 'swift_B':'D'}\n",
    "\n",
    "CSP_SNe = ['SN2004fe', 'SN2005bf', 'SN2006V', 'SN2007C', 'SN2007Y',\n",
    "           'SN2009bb',  'SN2008aq', 'SN2006T', 'SN2004gq', 'SN2004gt',\n",
    "           'SN2004gv','SN2006ep', 'SN2008fq', 'SN2006aa']\n",
    "\n",
    "exclude_filt = ['H', 'J', 'K', 'Ks','KS', 'Y']\n",
    "\n",
    "convert2mjd = (lambda x: float(x.replace('_REmangled_spec.txt','')\\\n",
    "                               .replace('_REmangled_spec_FL.txt','')\\\n",
    "                               .replace('_mangled_spec.txt','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lam_eff(wls, transmission):\n",
    "    return (integrate.trapz(transmission*wls, wls)/\\\n",
    "            integrate.trapz(transmission, wls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullMangledSeries_Class():\n",
    "    \"\"\"Class to load and mangle a single spectrum:\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, main_path, snname, type_=None, spec_file=None, \n",
    "                 mode = 'extend_spectra' , verbose=False, DELTA=50.):\n",
    "        \"\"\"\n",
    "        mode: 'extend_spectra'  or 'extrapolate_spectra' \n",
    "        \"\"\"\n",
    "        ## Initialise the class variables            \n",
    "        self.snname = snname\n",
    "        self.SNtype = type_\n",
    "        self.mode = mode\n",
    "        self.get_mangledspec_list()\n",
    "        self.DELTA = DELTA\n",
    "        self.verbose = verbose\n",
    "        self.create_extended_spec_folder() \n",
    "        self.path_fit_phot = OUTPUT_DIR+'/%s/fitted_phot_%s.dat'%(snname,snname)\n",
    "        \n",
    "    def get_mangledspec_list(self, extend_spectra = True, extrapolate_spectra=False, verbose=False):\n",
    "        if self.mode == 'extend_spectra':\n",
    "            mypath = OUTPUT_DIR+'/%s/mangled_spectra'%self.snname\n",
    "            onlyfiles = [f for f in os.listdir(mypath) \\\n",
    "                     if os.path.isfile(os.path.join(mypath, f))&('mangled_spec' in f)&('.txt' in f)]\n",
    "            self.mangledspec_list = onlyfiles\n",
    "            self.mangled_file_path = mypath+'/'\n",
    "        elif self.mode == 'extrapolate_spectra':\n",
    "            #mypath = self.main_path+'/results_template/%s/RE_mangled_spectra_2dim'%self.snname\n",
    "            mypath = OUTPUT_DIR+'/%s/mangled_spectra'%self.snname\n",
    "            onlyfiles = [f for f in os.listdir(mypath) \\\n",
    "#                         if os.path.isfile(os.path.join(mypath, f))&('REmangled_spec' in f)&('.txt' in f)&('_FL' not in f)]\n",
    "                         if os.path.isfile(os.path.join(mypath, f))&('mangled_spec' in f)&('.txt' in f)]\n",
    "            self.mangledspec_list = onlyfiles\n",
    "            self.mangled_file_path = mypath+'/'\n",
    "        return onlyfiles\n",
    "    \n",
    "    def load_mangledfile(self, file):\n",
    "        mangled_spec = np.genfromtxt(self.mangled_file_path+file, dtype=None,\\\n",
    "                                     encoding=\"utf-8\", names=['wls', 'flux', 'fluxerr', 'mang_mask'])\n",
    "        return mangled_spec\n",
    "\n",
    "          \n",
    "    def load_manglingfile(self, mjd):\n",
    "        #if not hasattr(self, \"results_mainpath\"):\n",
    "        #    self.check_mangling_file()\n",
    "        mangling_file = OUTPUT_DIR+'/%s/fitted_phot4mangling_%s.dat'%(self.snname,self.snname)\n",
    "        if not os.path.isfile(mangling_file):\n",
    "            raise Exception(\"I need the file with fitted photometry in order to mangle a spectrum\")\n",
    "        else:\n",
    "            phot4mangling = pd.read_csv(mangling_file, sep='\\t')\n",
    "            #print (phot4mangling)#self.phot4mangling = \n",
    "            specmjd= mjd#float(self.spec_file.replace('mangled_spec_','').replace('.txt',''))\n",
    "            self.phot4mangling = (phot4mangling[phot4mangling['spec_mjd']==specmjd])\n",
    "            if len(self.phot4mangling)<1:\n",
    "                raise Exception(\"\"\" ### ERROR: \n",
    "I looked in the file with the PHOTOMETRY for MANGLING \n",
    "(i.e. fitted_phot4mangling_SNNAME.dat).\n",
    "I was loading the photometry to mangle/extend the spectrum you are currently loading\n",
    "in the GRID. I found NO photometry for it... Maybe you should re run GP fit or check your list of spec.\"\"\")\n",
    "\n",
    "            elif len(self.phot4mangling)>1:\n",
    "                raise Exception(\"\"\" ###  TRICKY ERROR: \n",
    "I looked in the file with the PHOTOMETRY for MANGLING \n",
    "(i.e. fitted_phot4mangling_SNNAME.dat).\n",
    "I was loading the photometry to mangle/extend the spectrum you are currently loading\n",
    "in the GRID. I found two spectra at the exact same MJD and this is problem when\n",
    "I try to build the TIMExWLS grid with this.\n",
    "Check the phot4mangling.txt file and check if you're MJDs are correct and \n",
    "have the right decimals.\"\"\")\n",
    "            self.avail_filters = [col.replace('_fitflux','') for col in phot4mangling.columns\\\n",
    "                                  if col[-8:]=='_fitflux']        \n",
    "    \n",
    "    def create_extended_spec_folder(self):\n",
    "        save_plot_path = OUTPUT_DIR+'/%s/TwoDextended_spectra'%snname\n",
    "        if not os.path.exists(save_plot_path):\n",
    "            os.makedirs(save_plot_path)\n",
    "        else:\n",
    "            os.system('rm -rf %s'%save_plot_path)\n",
    "            os.makedirs(save_plot_path)\n",
    "\n",
    "        self.save_plot_path = save_plot_path\n",
    "        \n",
    "    def running_mean_std(self, x, y, delta_fix=500.):\n",
    "        #x = xnan[~np.isnan(ynan)]\n",
    "        #y = ynan[~np.isnan(ynan)]\n",
    "        \n",
    "        total_bins = int((x.max()-x.min())/delta_fix)\n",
    "        bins = np.linspace(x.min(),x.max(), total_bins)\n",
    "        try:\n",
    "            delta = bins[1]-bins[0]\n",
    "            idx  = np.digitize(x,bins)\n",
    "            running_median_x = np.array([np.mean(x[idx==k]) for k in np.arange(1,total_bins,1)])\n",
    "            running_mean = np.array([np.mean(y[idx==k]) for k in np.arange(1,total_bins,1)])\n",
    "            running_std = np.array([np.std(y[idx==k]) for k in np.arange(1,total_bins,1)])\n",
    "        except IndexError:\n",
    "            running_median_x = np.array([np.mean(x)])\n",
    "            running_mean = np.array([np.mean(y)])\n",
    "            running_std = np.array([np.std(y)])\n",
    "            \n",
    "        clean_running_median_x = np.copy(running_median_x)\n",
    "        clean_running_median_x[running_mean<0.] = np.nan\n",
    "        clean_running_mean = np.copy(running_mean)\n",
    "        clean_running_mean[running_mean<0.] = np.nan\n",
    "        clean_running_std = np.copy(running_std)\n",
    "        clean_running_std[running_mean<0.] = np.nan\n",
    "        \n",
    "        return clean_running_median_x, clean_running_mean, clean_running_std\n",
    "\n",
    "    def get_filt_transmission(self, filter_name):\n",
    "        \n",
    "        if 'swift' in filter_name:\n",
    "            filt_transm = np.genfromtxt(FILTER_PATH+'/Swift/%s.dat'%filter_name,\\\n",
    "                                                 dtype=None, encoding=\"utf-8\", names=['wls', 'flux'])\n",
    "        else:\n",
    "            filt_transm = np.genfromtxt(FILTER_PATH+'/GeneralFilters/%s.dat'%filter_name,\\\n",
    "                                                 dtype=None, encoding=\"utf-8\", names=['wls', 'flux'])\n",
    "        wls = filt_transm['wls']\n",
    "        transmission = filt_transm['flux']\n",
    "        return wls, transmission\n",
    "\n",
    "    def lam_eff(self, filter_name):\n",
    "        wls, transmission = self.get_filt_transmission(filter_name)\n",
    "        return (integrate.trapz(transmission*wls, wls)/\\\n",
    "            integrate.trapz(transmission, wls))\n",
    "\n",
    "    def load_phot_for_extention(self, file, anchor = False):\n",
    "        data_spec_mangled = self.load_mangledfile(file)\n",
    "        mjd = convert2mjd(file)\n",
    "        self.load_manglingfile(mjd)\n",
    "        all_fitted_phot_list=[]\n",
    "        fitted_phot_list=[]\n",
    "        fitted_photerr_list=[]\n",
    "        wls_eff=[]\n",
    "        filters4extention=[]\n",
    "        for filt in self.avail_filters:\n",
    "            lam_eff_value = self.lam_eff(filt)\n",
    "            fitted_phot = self.phot4mangling['%s_fitflux'%filt].values\n",
    "            fitted_phot_err = self.phot4mangling['%s_fitfluxerr'%filt].values\n",
    "            all_fitted_phot_list.append(fitted_phot[0])\n",
    "            inrange = self.phot4mangling['%s_inrange'%filt].values\n",
    "            #if (lam_eff_value>max(data_spec_mangled['wls'])+200)|(lam_eff_value<min(data_spec_mangled['wls']-200)):\n",
    "            if (lam_eff_value>max(data_spec_mangled['wls']))|(lam_eff_value<min(data_spec_mangled['wls'])):\n",
    "                if inrange:\n",
    "                    if self.verbose: print (filt, lam_eff_value, fitted_phot, mjd)\n",
    "                    fitted_phot_list.append(fitted_phot[0])\n",
    "                    fitted_photerr_list.append(fitted_phot_err[0])\n",
    "                    wls_eff.append(lam_eff_value)\n",
    "                    filters4extention.append(filt)\n",
    "\n",
    "        fitted_phot_list=np.array(fitted_phot_list)[np.argsort(wls_eff)]\n",
    "        fitted_photerr_list = np.array(fitted_photerr_list)[np.argsort(wls_eff)]\n",
    "        filters4extention=np.array(filters4extention)[np.argsort(wls_eff)]\n",
    "        wls_eff = np.sort(wls_eff)\n",
    "\n",
    "        self.phot4extention = {'mjd':mjd,'wls_eff':wls_eff,\\\n",
    "                                 'phot':fitted_phot_list,\\\n",
    "                                 'phot_err':fitted_photerr_list,\n",
    "                              'names':filters4extention}\n",
    "        return (self.phot4extention)\n",
    "    \n",
    "    def grid_all_spectraltimeseries(self):\n",
    "        ungrid_data_wls= []\n",
    "        ungrid_data_flux= []\n",
    "        ungrid_data_fluxerr= []\n",
    "        mjd =[]\n",
    "        \n",
    "        DELTA= self.DELTA#70.\n",
    "        for f in self.mangledspec_list:\n",
    "            spec = self.load_mangledfile(f)\n",
    "            if self.verbose: print (f, len(spec))\n",
    "            #smoothed_wls, smoothed_flux, smoothed_flux_err = \\\n",
    "            #        self.running_mean_std(spec['wls'], spec['flux'], delta_fix=DELTA)\n",
    "            \n",
    "            smoothed_wls = spec['wls'][~np.isnan(spec['flux'])]\n",
    "            smoothed_flux = spec['flux'][~np.isnan(spec['flux'])]\n",
    "            smoothed_flux_err = spec['fluxerr'][~np.isnan(spec['flux'])]\n",
    "            \n",
    "            ungrid_data_wls.append(smoothed_wls)\n",
    "            ungrid_data_flux.append(smoothed_flux)\n",
    "            ungrid_data_fluxerr.append(smoothed_flux_err)\n",
    "            mjd.append(convert2mjd(f))\n",
    "        grid_wls = np.arange(1590., 11050., DELTA)\n",
    "        grid_mjd = np.array(mjd)\n",
    "        grid_all = pd.DataFrame()\n",
    "        grid_all_err = pd.DataFrame()\n",
    "        \n",
    "        fig = plt.figure(figsize=(11,4))#(15,11))\n",
    "\n",
    "        for ii in range(len(ungrid_data_flux)):\n",
    "            grid_flux = np.ones(len(grid_wls))\n",
    "            grid_fluxerr = np.ones(len(grid_wls))\n",
    "\n",
    "            minwls = np.min(ungrid_data_wls[ii][~np.isnan(ungrid_data_wls[ii])])\n",
    "            maxwls = np.max(ungrid_data_wls[ii][~np.isnan(ungrid_data_wls[ii])])\n",
    "            data_mask = (grid_wls>=minwls)&(grid_wls<=maxwls)\n",
    "            flux_interp = np.interp(grid_wls[data_mask], ungrid_data_wls[ii], ungrid_data_flux[ii])\n",
    "            flux_interp_err = np.interp(grid_wls[data_mask], ungrid_data_wls[ii], ungrid_data_fluxerr[ii])\n",
    "            plt.plot(ungrid_data_wls[ii], ungrid_data_flux[ii], lw=0.5, color='k')#, label='unsmoothed spectra')\n",
    "            plt.plot(grid_wls[data_mask], flux_interp, '.r', ms=3)#, label='points in grid')\n",
    "            plt.fill_between(grid_wls[data_mask], flux_interp-flux_interp_err, \\\n",
    "                                 flux_interp+flux_interp_err, alpha=0.2, color='r')\n",
    "            grid_flux[data_mask] = flux_interp\n",
    "            grid_flux[~data_mask] = np.nan\n",
    "            grid_fluxerr[data_mask] = flux_interp_err\n",
    "            grid_fluxerr[~data_mask] = np.nan\n",
    "            grid_all[str(grid_mjd[ii])]=grid_flux\n",
    "            grid_all_err[str(grid_mjd[ii])]=grid_fluxerr\n",
    "        plt.title(self.snname+' Red: rebbined spectra for grid, Black: original unsmoothed spec')\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "        grid_all = grid_all.set_index(grid_wls)\n",
    "        grid_all.columns = grid_mjd\n",
    "        grid_all_err = grid_all_err.set_index(grid_wls)\n",
    "        grid_all_err.columns = grid_mjd\n",
    "        self.grids = [grid_wls, grid_mjd, grid_all, grid_all_err]\n",
    "        \n",
    "        return grid_wls, grid_mjd, grid_all, grid_all_err\n",
    "\n",
    "    \n",
    "    def band_flux_modified(self, filter_name, file):\n",
    "        \n",
    "        spec_flux = self.load_mangledfile(file)\n",
    "        \n",
    "        \n",
    "        if 'swift' in filter_name:\n",
    "            filt_transm = np.genfromtxt(FILTER_PATH+'/Swift/%s.dat'%filter_name,\\\n",
    "                                                 dtype=None, encoding=\"utf-8\", names=['wls', 'flux'])\n",
    "        elif self.snname in CSP_SNe:\n",
    "            filt_transm = np.genfromtxt(FILTER_PATH+'/Site3_CSP/%s.txt'%filter_name,\\\n",
    "                                                 dtype=None, encoding=\"utf-8\", names=['wls', 'flux'])\n",
    "        else:\n",
    "            filt_transm = np.genfromtxt(FILTER_PATH+'/GeneralFilters/%s.dat'%filter_name,\\\n",
    "                                                 dtype=None, encoding=\"utf-8\", names=['wls', 'flux'])\n",
    "        \n",
    "        lam_eff = calc_lam_eff(filt_transm['wls'], filt_transm['flux']) \n",
    "        filt_transm_interp_func = interpolate.interp1d(filt_transm['wls'], filt_transm['flux'], kind='linear')\n",
    "        cut_spec = [(spec_flux['wls']>min(filt_transm['wls']))&\\\n",
    "                     (spec_flux['wls']<max(filt_transm['wls']))]\n",
    "        cut_ext_spec = spec_flux[cut_spec]\n",
    "        filt_transm_interp = filt_transm_interp_func(cut_ext_spec['wls'])\n",
    "        #\n",
    "        raw_phot = integrate.trapz(filt_transm_interp*cut_ext_spec['flux'], cut_ext_spec['wls'])/\\\n",
    "                 integrate.trapz(filt_transm['flux'], filt_transm['wls'])\n",
    "        return lam_eff, raw_phot\n",
    "                \n",
    "        \n",
    "    def extend_grid_all_spectraltimeseries(self):\n",
    "        if not hasattr(self, 'grids'):\n",
    "            self.grid_all_spectraltimeseries()\n",
    "        \n",
    "        grid_notext = (self.grids[2]).copy()\n",
    "        grid_notext_err = (self.grids[3]).copy()\n",
    "\n",
    "        for f in self.get_mangledspec_list():\n",
    "            self.load_phot_for_extention(f)\n",
    "            phot4ext = self.phot4extention\n",
    "            for ind in range(len(phot4ext['wls_eff'])):#np.where(phot4ext['wls_eff']<3500.)[0]:\n",
    "                #if th raw associated with the wls doesnt exist create it\n",
    "                phot_cut = self.band_flux_modified(phot4ext['names'][ind], f)[1]\n",
    "                UVwls = phot4ext['wls_eff'][ind]\n",
    "                if phot4ext['names'][ind] in ['swift_UVW1', 'swift_UVW2', 'swift_UVM2']:\n",
    "                    phot_perc = (100.*phot_cut/(phot4ext['phot'][ind]))\n",
    "                else: phot_perc = 0.\n",
    "                if self.verbose: print ('UV synth versus obs phot %.2f'%phot_perc)\n",
    "                if self.verbose: print ('UV synth - obs phot %.2E'%(phot4ext['phot'][ind]-phot_cut))\n",
    "                if UVwls not in grid_notext.index:\n",
    "                    grid_notext.loc[UVwls]= np.nan*np.ones(grid_notext.shape[1])\n",
    "                    grid_notext_err.loc[UVwls]= np.nan*np.ones(grid_notext_err.shape[1])\n",
    "                if (phot_perc>1)&(phot_perc<99):\n",
    "                    grid_notext.loc[UVwls][phot4ext['mjd']] = phot4ext['phot'][ind]-phot_cut\n",
    "                else: grid_notext.loc[UVwls][phot4ext['mjd']] = phot4ext['phot'][ind]\n",
    "                grid_notext_err.loc[UVwls][phot4ext['mjd']] = phot4ext['phot_err'][ind]\n",
    "\n",
    "        LC_fit = self.open_LCfit_file()\n",
    "        filters_LC = [i for i in LC_fit.columns[1:] if '_err' not in i]\n",
    "        mjds_LC = LC_fit['MJD'].values\n",
    "        min_mjds_LC =[]\n",
    "        max_mjds_LC =[]\n",
    "        for band in filters_LC:\n",
    "            mjd_filt = mjds_LC[~np.isnan(LC_fit[band].values)]\n",
    "            min_mjds_LC.append(min(mjd_filt))\n",
    "            max_mjds_LC.append(max(mjd_filt))\n",
    "            if self.lam_eff(band) not in grid_notext.index:\n",
    "                grid_notext.loc[self.lam_eff(band)] = np.full(len(grid_notext.columns), np.nan)\n",
    "                grid_notext_err.loc[self.lam_eff(band)] = np.full(len(grid_notext.columns), np.nan)\n",
    "\n",
    "        if self.mode=='extrapolate_spectra':\n",
    "            def fill_gaps(min_mjd_phot, max_mjd_phot, spec_mjd, gap_size=2., fill_cadence=2.):\n",
    "                f = np.concatenate(([min_mjd_phot], spec_mjd, [max_mjd_phot]))\n",
    "                gaps_mjd = f - np.concatenate(([min_mjd_phot], f[:-1]))\n",
    "                extention=[]\n",
    "                for gap,offset in zip(gaps_mjd[gaps_mjd>gap_size], f[gaps_mjd>gap_size]):\n",
    "                    step = (gap/round(gap/fill_cadence,0))\n",
    "                    N = int(round(gap/fill_cadence,0))\n",
    "                    for i in range(N-1):\n",
    "                        extention.append(offset - (i+1)*step)\n",
    "                return extention\n",
    "            \n",
    "            if (self.snname in pre_bump):\n",
    "                early_extrap = np.linspace(min(min_mjds_LC),min(min_mjds_LC)+5., 15)\n",
    "                mjds_extention = np.sort(np.concatenate([early_extrap,\n",
    "                            fill_gaps(min(min_mjds_LC), max(max_mjds_LC), \n",
    "                                               grid_notext.columns)]))\n",
    "            else:\n",
    "                early_extrap = np.linspace(min(min_mjds_LC),min(min_mjds_LC)+5., 7)\n",
    "                mjds_extention = np.sort(np.concatenate([early_extrap,\n",
    "                            fill_gaps(min(min_mjds_LC), max(max_mjds_LC), \n",
    "                                               grid_notext.columns)]))\n",
    "            \n",
    "            if (max(mjds_extention-min(mjds_extention))>200.):\n",
    "                mjds_extention = mjds_extention[(mjds_extention-min(mjds_extention))<200.]\n",
    "                if self.verbose:\n",
    "                    print ('Max phase roughly %.2f.'%max((mjds_extention-min(mjds_extention))))\n",
    "                    print ('Chopping this to 200 days after first detection')\n",
    "            mjds_grid = np.sort(np.concatenate([mjds_extention,grid_notext.columns]))\n",
    "                   \n",
    "            for m in range(len(mjds_extention)):\n",
    "                if mjds_extention[m] not in grid_notext.columns:\n",
    "                    grid_notext[mjds_extention[m]] = np.full(len(grid_notext.index), np.nan)\n",
    "                    grid_notext_err[mjds_extention[m]] = np.full(len(grid_notext_err.index), np.nan)\n",
    "            #grid_notext.columns = mjds_grid\n",
    "            for band in filters_LC:\n",
    "                no_nan = [(~np.isnan(LC_fit[band].values))&(~np.isnan(LC_fit[band+'_err'].values))]\n",
    "                mjd_filt = mjds_LC[no_nan]\n",
    "                flux_filt = (LC_fit[band].values)[no_nan]\n",
    "                fluxerr_filt = (LC_fit[band+'_err'].values)[no_nan]\n",
    "                mask_grid = (mjds_grid>min(mjd_filt))&(mjds_grid<max(mjd_filt))\n",
    "                LC_val = np.full(len(mjds_grid), np.nan)\n",
    "                LC_val[mask_grid] = np.interp(mjds_grid[mask_grid], mjd_filt, flux_filt)\n",
    "                LCerr_val = np.full(len(mjds_grid), np.nan)\n",
    "                LCerr_val[mask_grid] = np.interp(mjds_grid[mask_grid], mjd_filt, fluxerr_filt)\n",
    "                for m in range(len(mjds_grid)):\n",
    "                    if (mjds_grid[m] in mjds_extention)&(m % 3 == 0 ):\n",
    "                        grid_notext[mjds_grid[m]].loc[self.lam_eff(band)] = LC_val[m]\n",
    "                        grid_notext_err[mjds_grid[m]].loc[self.lam_eff(band)] = LCerr_val[m]\n",
    "            \n",
    "        grid_ext = grid_notext.sort_index(inplace=False)\n",
    "        grid_ext_err = grid_notext_err.sort_index(inplace=False)\n",
    "\n",
    "        grid_ext_full = grid_ext.sort_index(axis=1, inplace=False)\n",
    "        grid_ext_err_full = grid_ext_err.sort_index(axis=1, inplace=False)\n",
    "        self.extended_grid = grid_ext_full\n",
    "        return grid_ext_full.index, grid_ext_full.columns, grid_ext_full, grid_ext_err_full\n",
    "\n",
    "    def get_filter_LC(self):\n",
    "        LC_fit = self.open_LCfit_file()\n",
    "        filters_LC = [i for i in LC_fit.columns[1:] if '_err' not in i]\n",
    "        self.avail_filters = filters_LC\n",
    "        return filters_LC\n",
    "        \n",
    "    def open_LCfit_file(self):\n",
    "        #if not hasattr(self, \"results_mainpath\"):\n",
    "        #    self.check_mangling_file()\n",
    "        LC_file = OUTPUT_DIR+'/%s/fitted_phot_%s.dat'%(self.snname,self.snname)\n",
    "        if not os.path.isfile(LC_file):\n",
    "            print (\"I need the file with fitted photometry in order to mangle a spectrum\")\n",
    "        else:\n",
    "            fittphot = pd.read_csv(LC_file, sep='\\t')\n",
    "        return fittphot\n",
    "    \n",
    "    def get_spec_mjd(self):\n",
    "        return np.array([convert2mjd(f) for f in self.get_mangledspec_list()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set some important parameters:\n",
    "kernel_wls_scale = 0.05\n",
    "kernel_time_scale = 0.3\n",
    "\n",
    "PRIOR_file = COCO_''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First initialize the class FullMangledSeries_Class\n",
    "spec_class = FullMangledSeries_Class(snname=snname, mode='extrapolate_spectra',\n",
    "                                     DELTA=30., verbose=False)\n",
    "# Load all the mangled spectra\n",
    "raw_numbers, raw_numbers_err, off_xa, off_ya , grid_ext_columns = GP2dim.prepare_grid(snname, spec_class, )\n",
    "\n",
    "# Trasform data to LOG, then rescale them to force them to be between 0,1 \n",
    "# Then reshape the grid to feed the 2dGP\n",
    "x2_data_norm = GP2dim.transform2LOG_reshape(spec_class, raw_numbers, raw_numbers_err, off_xa, off_ya)\n",
    "\n",
    "# Make some useful plots that helps to check the data you are using to interpolate the surface\n",
    "# These are saved in OUTPUT_DIR/SNname/TwoDextended_spectra\n",
    "GP2dim.make_plots(spec_class, y_data_nonan, y_data_nonan_err, x1_data_norm, x2_data_norm)\n",
    "\n",
    "# Set the prior\n",
    "Xprior, yprior = GP2dim.setPRIOR(spec_class, PRIOR_file=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the 2dim GP interpolation\n",
    "x1_fill, x2_fill, mu_fill, std_fill = GP2dim.run_2DGP_GRID(spec_class, y_data_nonan, y_data_nonan_err, x1_data_norm, x2_data_norm,\\\n",
    "\t\t kernel_wls_scale, kernel_time_scale, grid_ext_columns, \n",
    "         prior=True, points=Xprior, values=yprior)\n",
    "\n",
    "# Make some useful plots that helps to check the results\n",
    "# These are saved in OUTPUT_DIR/SNname/TwoDextended_spectra\n",
    "\n",
    "GP2dim.make_results_plots(spec_class, x1_fill, x2_fill, mu_fill, std_fill)\n",
    "mu_fill_conv, std_fill_conv, y_data_conv = GP2dim.transform_back_andPlot(spec_class, x1_fill, x2_fill, \n",
    "                                                                         mu_fill, std_fill, y_data_nonan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
