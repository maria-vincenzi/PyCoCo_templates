{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct Photometry for dust extinction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct broad-band photometry for Host and MW extinction (if this has not been already done.. 99% of the time the photometry is published before dust corrections).\n",
    "\n",
    "Assumptions: R_V always equal 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "COCO_PATH=os.environ['COCO_PATH']\n",
    "DATALC_PATH = COCO_PATH+\"/Inputs/Photometry/1_LCs_flux_raw/\"\n",
    "DATAINFO_PATH= COCO_PATH+\"Inputs/SNe_Info/\"\n",
    "FILTER_PATH = COCO_PATH+\"Inputs/Filters/\"\n",
    "\n",
    "OUTPUT_PATH = COCO_PATH+\"/Inputs/Photometry/2_LCs_dust_corrected/\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, COCO_PATH+'what_the_flux/')\n",
    "import what_the_flux as wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSP_SNe = ['SN2004fe', 'SN2005bf', 'SN2006V', 'SN2007C', 'SN2007Y',\n",
    "           'SN2009bb',  'SN2008aq', 'SN2006T', 'SN2004gq', 'SN2004gt',\n",
    "           'SN2004gv','SN2006ep', 'SN2008fq', 'SN2006aa']\n",
    "\n",
    "Vega_filt = ['Bessell_U', 'Bessell_B','Bessell_V','Bessell_R','Bessell_I', \n",
    "            'swift_UVW2', 'swift_UVM2', 'swift_UVW1', 'swift_U', 'swift_B','swift_V',\n",
    "            'Y', 'H', 'J', 'K', 'Ks']\n",
    "AB_filt = ['sdss_u', 'sdss_g','sdss_r','sdss_i','sdss_z', \n",
    "            \"sdss_u'\", \"sdss_g'\", \"sdss_r'\", \"sdss_i'\", \"sdss_z'\"]\n",
    "\n",
    "exclude_filt = ['H', 'J', 'K', 'Ks','KS', 'Y']\n",
    "info_objects = pd.read_csv(DATAINFO_PATH+'info.dat', comment='#', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>z</th>\n",
       "      <th>RA</th>\n",
       "      <th>Dec</th>\n",
       "      <th>FullType</th>\n",
       "      <th>Type</th>\n",
       "      <th>Rich_Type</th>\n",
       "      <th>EBV_MW</th>\n",
       "      <th>EBV_host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iPTF13bvn</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>15:00:00.15</td>\n",
       "      <td>+01:52:53.17</td>\n",
       "      <td>Ib</td>\n",
       "      <td>Ib</td>\n",
       "      <td>Ib</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name        z           RA           Dec FullType Type Rich_Type  \\\n",
       "0  iPTF13bvn  0.00449  15:00:00.15  +01:52:53.17       Ib   Ib        Ib   \n",
       "\n",
       "   EBV_MW  EBV_host  \n",
       "0   0.051      0.17  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SNPhotometryClass():\n",
    "    \"\"\"Class with photometry for each object:\n",
    "            - load the photometry from the DATA folder\n",
    "            - get the phootmetry in each filter\n",
    "            - plot the raw photometry \n",
    "            - fit the photometry using GP\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lc_path, snname, verbose=False):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.lc_data_path = lc_path+'/'\n",
    "        self.snname = snname   \n",
    "        self.set_data_directory(verbose)\n",
    "\n",
    "    def set_data_directory(self, verbose):\n",
    "        \"\"\"\n",
    "        Set a new data directory path.\n",
    "        Enables the data directory to be changed by the user.\n",
    "        \"\"\"\n",
    "        SNphotometry_PATH = os.path.join(self.lc_data_path, '%s.dat'%self.snname)\n",
    "        \n",
    "        try:\n",
    "            if verbose: print('Looking for Photometry for %s in%s'%(self.snname, SNphotometry_PATH))\n",
    "            if os.path.isfile(SNphotometry_PATH):\n",
    "                if verbose: print ('Got it!')\n",
    "                self.sn_rawphot_file = SNphotometry_PATH\n",
    "                pass\n",
    "            else:\n",
    "                if not os.path.isdir(self.lc_data_path):\n",
    "                    print ('I cant find the directory with photometry. Check %s'%self.lc_data_path)\n",
    "                    pass\n",
    "                else: \n",
    "                    print ('I cant find the file with photometry. Check %s'%SNphotometry_PATH)\n",
    "                    pass\n",
    "    \n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "\n",
    "    def load(self, verbose = False):\n",
    "        \"\"\"\n",
    "        Loads a single photometry file.\n",
    "        with ('MJD', 'flux', 'flux_err', 'filter')\n",
    "        \n",
    "        Parameters\n",
    "        - verbose\n",
    "        ----------\n",
    "        Returns\n",
    "        - photometry in all filters\n",
    "        -------\n",
    "        \"\"\"\n",
    "        if verbose: print('Loading %s'%self.sn_rawphot_file)\n",
    "        try:\n",
    "            lc_file = pd.read_csv(self.sn_rawphot_file,\n",
    "                                    dtype=None,encoding=\"utf-8\")\n",
    "            mask_filt = np.array([f not in exclude_filt for f in lc_file['band']])\n",
    "            lc_no_badfilters = lc_file[mask_filt]\n",
    "            mask_filt = np.array([~np.isnan(f) for f in lc_no_badfilters['Flux']])\n",
    "            self.phot = lc_no_badfilters[mask_filt]\n",
    "            self.avail_filters = np.unique(self.phot['band'])\n",
    "            if verbose: print ('Photometry loaded')\n",
    "\n",
    "        except Exception as e:\n",
    "            print (e)\n",
    "            print ('Are you sure you gave me the right format? Check documentation in case.')\n",
    "\n",
    "    def get_availfilter(self, verbose = False):\n",
    "        \"\"\"\n",
    "        get available filter for this SN\n",
    "        \"\"\"\n",
    "        #if photometry is not already loaded, load it!\n",
    "        if (not hasattr(self, \"phot\"))|(not hasattr(self, \"avail_filters\")):\n",
    "            self.load()\n",
    "        return self.avail_filters\n",
    "        \n",
    "    def get_singlefilter(self, single_filter, verbose = False):\n",
    "        \"\"\"\n",
    "        Loads from photometry file just 1 filter photometry.\n",
    "        with ('MJD', 'flux', 'flux_err', 'filter')\n",
    "        \n",
    "        Parameters\n",
    "        - verbose\n",
    "        ----------\n",
    "        Returns\n",
    "        - photometry in all filters\n",
    "        -------\n",
    "        \"\"\"\n",
    "        #if photometry is not already loaded, load it!\n",
    "        if not hasattr(self, \"phot\"):\n",
    "            self.load()\n",
    "\n",
    "        if not (isinstance(single_filter, str)):\n",
    "            print ('Single filter string please')\n",
    "            return None\n",
    "        \n",
    "        if single_filter not in self.avail_filters:\n",
    "            if verbose: print ('Looks like the filter you are looking for is not available')\n",
    "            return None\n",
    "        \n",
    "        filt_index = self.phot['band']==single_filter\n",
    "        return self.phot[filt_index]\n",
    "        \n",
    "    def corr_dust_singlefilter(self, filter_name):\n",
    "        if not hasattr(self, \"corr_factors\"):\n",
    "            self.corr_factors = {}\n",
    "        corr_factors_dict = self.corr_factors            \n",
    "\n",
    "        self.get_dust()\n",
    "        self.get_redshift()\n",
    "        RV = RV_dict[self.SNType]\n",
    "\n",
    "        if 'swift' in filter_name:\n",
    "            w,t = w,t=wtf.loadFilter(FILTER_PATH+'/Swift/%s.dat'%filter_name)\n",
    "        elif self.snname in CSP_SNe:\n",
    "            w,t = w,t=wtf.loadFilter(FILTER_PATH+'/Site3_CSP/%s.txt'%filter_name)\n",
    "        else:\n",
    "            w,t = w,t=wtf.loadFilter(FILTER_PATH+'/GeneralFilters/%s.dat'%filter_name)\n",
    "            \n",
    "        w_SNframe = w/(1.+self.redshift)\n",
    "        \n",
    "        if filter_name in Vega_filt: band = wtf.Band_Vega(w_SNframe,t)\n",
    "        elif filter_name in AB_filt: band = wtf.Band_AB(w_SNframe,t)\n",
    "        ext_corr_Host = (1./band.extinction(self.Hostebv, 'CCM', r_v = RV)).value\n",
    "        print (filter_name, 'RV',RV, 'Host dust correction %.3f'%ext_corr_Host)\n",
    "\n",
    "        if filter_name in Vega_filt: band = wtf.Band_Vega(w,t)\n",
    "        elif filter_name in AB_filt: band = wtf.Band_AB(w,t)\n",
    "        ext_corr_MW = (1./band.extinction(self.MWebv, 'CCM')).value\n",
    "\n",
    "        corr_factors_dict[filter_name] = ext_corr_Host*ext_corr_MW\n",
    "        self.corr_factors = corr_factors_dict           \n",
    "\n",
    "    \n",
    "    def get_dust(self):\n",
    "        if self.snname not in info_objects.Name.values:\n",
    "            raise Exception('This SN is not in the info.dat file')\n",
    "        else:\n",
    "            info_singleobj = info_objects[info_objects.Name==self.snname]\n",
    "            self.MWebv = info_singleobj['EBV_MW'].values[0]\n",
    "            Host_ebv = info_singleobj['EBV_host'].values[0]\n",
    "            self.Hostebv = Host_ebv\n",
    "            self.SNType = (info_singleobj['Type'].values[0])\n",
    "        \n",
    "    def get_redshift(self):\n",
    "        info_singleobj = info_objects[info_objects.Name==self.snname]\n",
    "        self.redshift = info_singleobj['z'].values[0]\n",
    "\n",
    "    def correct_final_LC(self, name_file = None):\n",
    "        for ff in self.get_availfilter():\n",
    "            self.corr_dust_singlefilter(ff)\n",
    "        \n",
    "        lc_file = pd.DataFrame(self.phot)\n",
    "        corr_dust_array = [self.corr_factors[f] for f in lc_file['band']]\n",
    "        lc_file['Flux_corr'] = corr_dust_array*lc_file['Flux'].values\n",
    "        lc_file['Flux_corr_err'] = corr_dust_array*lc_file['Flux_err'].values\n",
    "\n",
    "        return lc_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dust correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are assuming RV = 3.1\n",
    "RV_dict = {'Ic':3.1 , 'Ic-BL':3.1, 'Ib':3.1, 'IIb':3.1, 'II':3.1, 'IIn':3.1}\n",
    "\n",
    "# If you want to do something more sophisticated and set a different R_V for different SN types set this:\n",
    "# RV_dict = {'Ic':4.3 , 'Ic-BL':4.3, 'Ib':2.6, 'IIb':1.1, 'II':3.1, 'IIn':3.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "snname = 'iPTF13bvn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for Photometry for iPTF13bvn in/Volumes/TOSHIBAEXT/PyCoCo_templates//Inputs/Photometry/1_LCs_flux_raw//iPTF13bvn.dat\n",
      "Got it!\n"
     ]
    }
   ],
   "source": [
    "sn_phot = SNPhotometryClass(lc_path=DATALC_PATH,snname=snname, verbose=True)\n",
    "sn_phot.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bessell_B RV 3.1 Host dust correction 1.910\n",
      "Bessell_I RV 3.1 Host dust correction 1.338\n",
      "Bessell_R RV 3.1 Host dust correction 1.494\n",
      "Bessell_U RV 3.1 Host dust correction 2.152\n",
      "Bessell_V RV 3.1 Host dust correction 1.635\n",
      "sdss_g' RV 3.1 Host dust correction 1.794\n",
      "sdss_i' RV 3.1 Host dust correction 1.378\n",
      "sdss_r' RV 3.1 Host dust correction 1.529\n",
      "sdss_z' RV 3.1 Host dust correction 1.270\n"
     ]
    }
   ],
   "source": [
    "sn_phot.get_availfilter()\n",
    "df = sn_phot.correct_final_LC()\n",
    "\n",
    "df_to_print = df[['MJD', 'band', 'Flux_corr', 'Flux_corr_err', 'FilterSet', 'Instr']]\n",
    "df_to_print.to_csv(OUTPUT_PATH+'/%s.dat'%snname, na_rep='nan', index=False, \n",
    "                           header=['#MJD','band','Flux','Flux_err','FilterSet', 'Instr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
